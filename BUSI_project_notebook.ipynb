{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alifabdullah/DataScience/blob/main/BUSI_project_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, time, shutil, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch, torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import timm\n"
      ],
      "metadata": {
        "id": "id1wZPq7K_pB"
      },
      "id": "id1wZPq7K_pB",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- CONFIG ---"
      ],
      "metadata": {
        "id": "eh2lbKAvLZSz"
      },
      "id": "eh2lbKAvLZSz"
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"sabahesaraki/breast-ultrasound-images-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Cz64-rd6Y4c",
        "outputId": "19356c04-a74d-4c97-f41a-f3620a9887e9"
      },
      "id": "6Cz64-rd6Y4c",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'breast-ultrasound-images-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/breast-ultrasound-images-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT'\n",
        "unique_classes = []\n",
        "for path in os.listdir(BASE_PATH):\n",
        "    unique_classes.append(path)\n",
        "print(unique_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-10-04T08:05:11.189443Z",
          "iopub.execute_input": "2025-10-04T08:05:11.189744Z",
          "iopub.status.idle": "2025-10-04T08:05:11.202236Z",
          "shell.execute_reply.started": "2025-10-04T08:05:11.189704Z",
          "shell.execute_reply": "2025-10-04T08:05:11.201421Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2Z77mWMQjq-",
        "outputId": "0c73bf6c-0dd2-43de-f879-f5e214dad3ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['benign', 'normal', 'malignant']\n"
          ]
        }
      ],
      "execution_count": 25,
      "id": "q2Z77mWMQjq-"
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_DIR = \"./outputs\"\n",
        "IMG_SIZE = 224\n",
        "BATCH = 32\n",
        "EPOCHS = 8\n",
        "LR = 1e-4\n",
        "SEED = 42\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deZpPHfpKdrx",
        "outputId": "960abc8c-c1eb-4650-c1db-4c2b225aa3fa"
      },
      "id": "deZpPHfpKdrx",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a5e393397d0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### --- Gather dataset ---"
      ],
      "metadata": {
        "id": "JNL4s52oNyFr"
      },
      "id": "JNL4s52oNyFr"
    },
    {
      "cell_type": "code",
      "source": [
        "imgs, labels = [], []\n",
        "for idx, tumor in enumerate(tumor_types):\n",
        "    folder = Path(BASE_PATH) / tumor\n",
        "    for f in folder.glob(\"*.png\"):\n",
        "        if \"mask\" in f.name.lower():  # skip segmentation masks\n",
        "            continue\n",
        "        imgs.append(str(f)); labels.append(idx)\n",
        "\n",
        "print(f\"Found {len(imgs)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZg0TaEEL0_y",
        "outputId": "394266ef-640c-47aa-dc9a-662372e11ee6"
      },
      "id": "HZg0TaEEL0_y",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 780 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### --- Dataset class ---"
      ],
      "metadata": {
        "id": "DeLn7kqFN0C6"
      },
      "id": "DeLn7kqFN0C6"
    },
    {
      "cell_type": "code",
      "source": [
        "class ImgDataset(Dataset):\n",
        "    def __init__(self, paths, labels, transform=None):\n",
        "        self.paths = paths; self.labels = labels; self.transform = transform\n",
        "    def __len__(self): return len(self.paths)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert('RGB')\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, self.labels[idx]\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "i4PEePgNNzkL"
      },
      "id": "i4PEePgNNzkL",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train/Val/Test split"
      ],
      "metadata": {
        "id": "46_USzSzONhz"
      },
      "id": "46_USzSzONhz"
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_tmp, y_tr, y_tmp = train_test_split(imgs, labels, test_size=0.3, stratify=labels, random_state=SEED)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=SEED)\n",
        "\n",
        "train_loader = DataLoader(ImgDataset(X_tr,y_tr,transform), batch_size=BATCH, shuffle=True)\n",
        "val_loader   = DataLoader(ImgDataset(X_val,y_val,transform), batch_size=BATCH, shuffle=False)\n",
        "test_loader  = DataLoader(ImgDataset(X_test,y_test,transform), batch_size=BATCH, shuffle=False)\n",
        "\n",
        "print(\"Train/Val/Test:\", len(X_tr), len(X_val), len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSc7d3wbOM-N",
        "outputId": "114ca07c-aa84-4e12-dc1e-6707f4c2c509"
      },
      "id": "qSc7d3wbOM-N",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Val/Test: 546 117 117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### --- Model ---"
      ],
      "metadata": {
        "id": "CveO7prwPE8-"
      },
      "id": "CveO7prwPE8-"
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = len(tumor_types)\n",
        "def make_model():\n",
        "    try:\n",
        "        m = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=NUM_CLASSES)\n",
        "        print(\"Using ViT from timm\")\n",
        "    except:\n",
        "        print(\"Fallback: Simple CNN\")\n",
        "        class SimpleCNN(nn.Module):\n",
        "            def __init__(self):\n",
        "                super().__init__()\n",
        "                self.feats = nn.Sequential(\n",
        "                    nn.Conv2d(3,32,3,padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    nn.Conv2d(32,64,3,padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    nn.Conv2d(64,128,3,padding=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.AdaptiveAvgPool2d(1)\n",
        "                )\n",
        "                self.fc = nn.Linear(128, NUM_CLASSES)\n",
        "            def forward(self,x):\n",
        "                x=self.feats(x); return self.fc(x.view(x.size(0),-1))\n",
        "        m = SimpleCNN()\n",
        "    return m.to(device)\n",
        "\n",
        "model = make_model()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAhpJG8oOQb6",
        "outputId": "66d763f7-dea2-4b84-f8e2-6069e74b7fdb"
      },
      "id": "sAhpJG8oOQb6",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using ViT from timm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### --- Training ---"
      ],
      "metadata": {
        "id": "HpcbCjIXPofa"
      },
      "id": "HpcbCjIXPofa"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch():\n",
        "    model.train(); losses=[]; correct=0; total=0\n",
        "    for x,y in train_loader:\n",
        "        x,y = x.to(device), torch.tensor(y).to(device)\n",
        "        opt.zero_grad()\n",
        "        out = model(x); loss = criterion(out,y)\n",
        "        loss.backward(); opt.step()\n",
        "        losses.append(loss.item())\n",
        "        correct += (out.argmax(1)==y).sum().item(); total += y.size(0)\n",
        "    return np.mean(losses), correct/total\n",
        "\n",
        "def eval_loader(loader):\n",
        "    model.eval(); losses=[]; preds=[]; gts=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x,y = x.to(device), torch.tensor(y).to(device)\n",
        "            out = model(x); loss = criterion(out,y)\n",
        "            losses.append(loss.item())\n",
        "            preds.extend(out.argmax(1).cpu().numpy()); gts.extend(y.cpu().numpy())\n",
        "    acc = (np.array(preds)==np.array(gts)).mean()\n",
        "    return np.mean(losses), acc, preds, gts\n",
        "\n",
        "history={'train_loss':[],'val_loss':[],'train_acc':[],'val_acc':[]}\n",
        "best_val=0; best_path=os.path.join(OUT_DIR,\"best_model.pth\")\n",
        "\n",
        "for ep in range(EPOCHS):\n",
        "    tr_loss,tr_acc=train_epoch()\n",
        "    val_loss,val_acc,_,_=eval_loader(val_loader)\n",
        "    history['train_loss'].append(tr_loss); history['val_loss'].append(val_loss)\n",
        "    history['train_acc'].append(tr_acc); history['val_acc'].append(val_acc)\n",
        "    print(f\"Epoch {ep+1}/{EPOCHS} tr_acc={tr_acc:.3f} val_acc={val_acc:.3f}\")\n",
        "    if val_acc>best_val: torch.save(model.state_dict(),best_path); best_val=val_acc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oFzNZHIPoKz",
        "outputId": "25b206f5-d41c-4ecf-a78b-408d38718523"
      },
      "id": "_oFzNZHIPoKz",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2644282010.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x,y = x.to(device), torch.tensor(y).to(device)\n",
            "/tmp/ipython-input-2644282010.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x,y = x.to(device), torch.tensor(y).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8 tr_acc=0.482 val_acc=0.556\n",
            "Epoch 2/8 tr_acc=0.566 val_acc=0.573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Test ---"
      ],
      "metadata": {
        "id": "SCKrHfGrQB7a"
      },
      "id": "SCKrHfGrQB7a"
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(best_path))\n",
        "test_loss,test_acc,preds,targets=eval_loader(test_loader)\n",
        "print(\"Test acc:\",test_acc)\n",
        "print(classification_report(targets,preds,target_names=tumor_types))\n"
      ],
      "metadata": {
        "id": "w9QiKUeiQBVj"
      },
      "id": "w9QiKUeiQBVj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### --- Plots ---\n"
      ],
      "metadata": {
        "id": "2R-MT7UDZcx0"
      },
      "id": "2R-MT7UDZcx0"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(); plt.plot(history['train_acc'],label=\"train\"); plt.plot(history['val_acc'],label=\"val\"); plt.legend(); plt.title(\"Accuracy\"); plt.show()\n",
        "plt.figure(); plt.plot(history['train_loss'],label=\"train\"); plt.plot(history['val_loss'],label=\"val\"); plt.legend(); plt.title(\"Loss\"); plt.show()\n",
        "\n",
        "import seaborn as sns\n",
        "cm = confusion_matrix(targets,preds)\n",
        "sns.heatmap(cm,annot=True,fmt=\"d\",cmap=\"Blues\",xticklabels=tumor_types,yticklabels=tumor_types)\n",
        "plt.title(\"Confusion Matrix\"); plt.show()"
      ],
      "metadata": {
        "id": "IyYZX34XZcIY"
      },
      "id": "IyYZX34XZcIY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}